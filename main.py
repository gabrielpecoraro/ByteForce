import os
import pickle
import torch
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from Loader.load_pdf import PDFLoader
from Loader.embedding import EmbeddingGenerator

# Path to the folder containing your PDFs
dataset_path = "./Dataset"

# Check if GPU is available
device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
print(device)

print("Start")

# Initialize PDFLoader and process the dataset
loader = PDFLoader()
loader.process_dataset(dataset_path)
pkl_folder = os.path.join(dataset_path, "pkl")

# Collect all .pkl files generated by PDFLoader
pkl_files = [
    os.path.join(pkl_folder, f) for f in os.listdir(pkl_folder) if f.endswith(".pkl")
]

# Initialize EmbeddingGenerator and generate embeddings for all .pkl files
embedding_generator = EmbeddingGenerator()
all_chunks = embedding_generator.process_pkl_files(pkl_files)
chunk_vectors = embedding_generator.embeddings.embed_documents(all_chunks)

# Debug print to check if all_chunks is empty
print(f"Number of chunks: {len(all_chunks)}")
text_embeddings = list(zip([chunk for chunk in all_chunks], chunk_vectors))

# Save the FAISS index to a directory within the dataset folder
faiss_index_dir = os.path.join(dataset_path, "faiss_index")
embedding_generator.save_faiss_index(all_chunks, faiss_index_dir)

print("Finished")
